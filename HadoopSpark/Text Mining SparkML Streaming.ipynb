{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# An\u00e1lisis de sentimiento"}, {"cell_type": "markdown", "metadata": {}, "source": " \n## Aprendizaje supervisado: un problema de clasificaci\u00f3n\n\nLos algoritmos de aprendizaje supervisado utilizan datos etiquetados en los que tanto la entrada como el resultado objetivo (*etiqueta*), se proporcionan al algoritmo. El aprendizaje supervisado tambi\u00e9n se denomina modelado predictivo o an\u00e1lisis predictivo, porque crea un modelo que es capaz de realizar predicciones.\n\nUn algoritmo de clasificaci\u00f3n toma un conjunto de datos con etiquetas conocidas y caracter\u00edsticas predeterminadas, y aprende c\u00f3mo etiquetar nuevos registros en funci\u00f3n de esa informaci\u00f3n. Las caracter\u00edsticas definen a cada individuo (cada registro, fila de nuestros datos, tambi\u00e9n llamado *ejemplo*). La etiqueta es la salida que corresponde con esas caracter\u00edsticas. \n\nVeamos un ejemplo de clasificaci\u00f3n de texto. \n* \u00bfQu\u00e9 estamos tratando de predecir?\n  * Si una revisi\u00f3n de producto es positiva o negativa.\n  * Retrasada es la etiqueta: 1 para positivo 0 para negativo\n* \u00bfCu\u00e1les son las propiedades que puede utilizar para hacer predicciones?\n  * Las palabras del texto de revisi\u00f3n se utilizan como caracter\u00edsticas para descubrir similitudes y categorizar el sentimiento del texto del cliente como positivo o negativo.\n\n### Regresi\u00f3n log\u00edstica\n\nLa regresi\u00f3n log\u00edstica es un m\u00e9todo popular para predecir una respuesta binaria. Es un caso especial de modelos lineales generalizados que predice la probabilidad de que la clase asociada a un ejemplo sea una de las clases, o bien la otra (suele usarse casi siempre en problemas donde los registros pertenecen a una de entre dos clases posibles). La regresi\u00f3n log\u00edstica mide la relaci\u00f3n entre la \"etiqueta\" ***Y*** y las \"caracter\u00edsticas\" ***X*** a trav\u00e9s la estimaci\u00f3n de probabilidades mediante una funci\u00f3n log\u00edstica. El modelo predice una probabilidad que se utiliza para predecir la clase a la que pertenece ese ejemplo.\n\n### Dataset de opiniones de Amazon\n\nSe puede descargar desde <a target=\"_blank\" href=\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Sports_and_Outdoors_5.json.gz\">aqu\u00ed</a>"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "!wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Sports_and_Outdoors_5.json.gz\n!gunzip reviews_Sports_and_Outdoors_5.json.gz\n!hdfs dfs -copyFromLocal reviews_Sports_and_Outdoors_5.json gs://<nombrebucket>/datos"}, {"cell_type": "markdown", "metadata": {}, "source": "Tenemos un conjunto de datos formado por textos breves escritos por clientes de Amazon al recibir su compra, en los cuales cada cliente expresa su opini\u00f3n sobre el producto adquirido. Cada registro (cada fila del dataset) representa la opini\u00f3n frente a alg\u00fan producto. El texto tiene, por un lado, una columna en la que el cliente da un titular o resumen a su revisi\u00f3n, y por otro, una columna con un texto m\u00e1s largo donde expresa el detalle.\n\nEl dataset se encuentra en formato JSON-line en el que cada l\u00ednea es un JSON completo, como el del siguiente ejemplo:\n\n`{\"reviewerID\": \"A1PUWI9RTQV19S\", \"asin\": \"B003Y5C132\", \"reviewerName\": \"kris\", \"helpful\": [0, 1], \"reviewText\": \"A little small in hind sight, but I did order a .30 cal box. Good condition, and keeps my ammo organized.\", \"overall\": 5.0, \"summary\": \"Nice ammo can\", \"unixReviewTime\": 1384905600, \"reviewTime\": \"11 20, 2013\"}`\n\nque, como vemos, sigue el siguiente esquema:\n\n* **reviewerID** - identificador del cliente, p.ej. A2SUAM1J3GNN3B\n* **asin** - identificador del producto, p.ej. 0000013714\n* **reviewerName** - nombre del cliente\n* **helpful** - valoraci\u00f3n del grado de utilidad de esta opini\u00f3n, expresado como un n\u00famero real entre 0 y 1, p.ej. 2/3\n* **reviewText** - texto de la opini\u00f3n\n* **overall** - valoraci\u00f3n que da el cliente al producto, entre 1 y 5\n* **summary** - resumen de la revisi\u00f3n\n* **unixReviewTime** - instante en el que se cre\u00f3 esta opini\u00f3n (expresado como unix time)\n* **reviewTime** - instante en el que se cre\u00f3 esta opini\u00f3n (formato en crudo)"}, {"cell_type": "code", "execution_count": 3, "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "from pyspark.sql import functions as F\nfrom pyspark.sql import types as T"}, {"cell_type": "code", "execution_count": 4, "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+----------+-------+--------------------+--------------------+--------------+--------------------+\n|      asin|overall|          reviewText|             summary|unixReviewTime|            reviewTS|\n+----------+-------+--------------------+--------------------+--------------+--------------------+\n|1881509818|    5.0|This came in on t...|      Woks very good|    1390694400|Woks very good Th...|\n|1881509818|    5.0|I had a factory G...|Works as well as ...|    1328140800|Works as well as ...|\n|1881509818|    4.0|If you don't have...|It's a punch, tha...|    1330387200|It's a punch, tha...|\n|1881509818|    4.0|This works no bet...|It's a punch with...|    1328400000|It's a punch with...|\n|1881509818|    4.0|I purchased this ...|Ok,tool does what...|    1366675200|Ok,tool does what...|\n+----------+-------+--------------------+--------------------+--------------+--------------------+\nonly showing top 5 rows\n\n"}], "source": "rawDF = spark.read\\\n           .option(\"inferSchema\", \"true\")\\\n           .json(\"gs://ucmbucket2023/datos/reviews_Sports_and_Outdoors_5.json\")\n\n# add column combining summary and review text, drop some others \ndf = rawDF.withColumn(\"reviewTS\",\n                      F.concat(F.col(\"summary\"), F.lit(\" \"), F.col(\"reviewText\")))\\\n          .drop(\"helpful\", \"reviewerID\", \"reviewerName\", \"reviewTime\")\n\ndf.show(5)"}, {"cell_type": "code", "execution_count": 5, "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- asin: string (nullable = true)\n |-- overall: double (nullable = true)\n |-- reviewText: string (nullable = true)\n |-- summary: string (nullable = true)\n |-- unixReviewTime: long (nullable = true)\n |-- reviewTS: string (nullable = true)\n\n"}], "source": "df.printSchema()"}, {"cell_type": "markdown", "metadata": {}, "source": "Vamos a quitar las opiniones neutras (con valoraci\u00f3n 3 sobre 5) para evitar posibles confusiones. Cualquier opini\u00f3n con valoraci\u00f3n 1 \u00f3 2 ser\u00e1 considerada negativa, mientras que una opini\u00f3n con valoraci\u00f3n 4 \u00f3 5 ser\u00e1 considerada positiva. Estas dos clases (negativa y positiva) ser\u00e1n los posibles valores de nuestra columna objetivo."}, {"cell_type": "code", "execution_count": 6, "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----------+-------+--------------------+--------------------+--------------+--------------------+\n|      asin|overall|          reviewText|             summary|unixReviewTime|            reviewTS|\n+----------+-------+--------------------+--------------------+--------------+--------------------+\n|1881509818|    5.0|This came in on t...|      Woks very good|    1390694400|Woks very good Th...|\n|1881509818|    5.0|I had a factory G...|Works as well as ...|    1328140800|Works as well as ...|\n|1881509818|    4.0|If you don't have...|It's a punch, tha...|    1330387200|It's a punch, tha...|\n|1881509818|    4.0|This works no bet...|It's a punch with...|    1328400000|It's a punch with...|\n|1881509818|    4.0|I purchased this ...|Ok,tool does what...|    1366675200|Ok,tool does what...|\n|1881509818|    5.0|Needed this tool ...|Glock punch tool ...|    1351814400|Glock punch tool ...|\n|1881509818|    5.0|If u don't have i...|          Great tool|    1402358400|Great tool If u d...|\n|2094869245|    4.0|This light will n...|             Bright!|    1377907200|Bright! This ligh...|\n|2094869245|    5.0|Light and laser t...|             Be seen|    1369612800|Be seen Light and...|\n|2094869245|    5.0|Does everything i...|Bicycle rear tail...|    1383350400|Bicycle rear tail...|\n|2094869245|    4.0|Very bright.  I w...|          Great lite|    1399420800|Great lite Very b...|\n|2094869245|    5.0|Mine arrived with...|For $11, it's a b...|    1389657600|For $11, it's a b...|\n|2094869245|    4.0|It works great it...|               Bulky|    1387497600|Bulky It works gr...|\n|2094869245|    5.0|I love this light...|            Love it!|    1379462400|Love it! I love t...|\n|2094869245|    5.0|Bit bulky. One bu...|       Bulky but....|    1389830400|Bulky but.... Bit...|\n|2094869245|    5.0|it is bright and ...|     rear bike light|    1386374400|rear bike light i...|\n|2094869245|    4.0|A mice bright lig...|Needed a little m...|    1383523200|Needed a little m...|\n|2094869245|    4.0|Had one ride on t...|Good light for th...|    1384214400|Good light for th...|\n|7245456259|    2.0|So it worked well...|resistance was go...|    1395964800|resistance was go...|\n|7245456259|    5.0|My girlfriend is ...|Girlfriend loves ...|    1378339200|Girlfriend loves ...|\n+----------+-------+--------------------+--------------------+--------------+--------------------+\nonly showing top 20 rows\n\n"}], "source": "no_neutral_df = df.filter(\"overall !=3\")\nno_neutral_df.show()"}, {"cell_type": "markdown", "metadata": {}, "source": "La funci\u00f3n `describe()` nos da estad\u00edsticas de resumen acerca de una o varias columnas num\u00e9ricas."}, {"cell_type": "code", "execution_count": 7, "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 4:=============================>                             (1 + 1) / 2]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-------+------------------+\n|summary|           overall|\n+-------+------------------+\n|  count|            272266|\n|   mean|  4.51664548639933|\n| stddev|0.9344777791100664|\n|    min|               1.0|\n|    max|               5.0|\n+-------+------------------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "no_neutral_df.describe(\"overall\").show()"}, {"cell_type": "code", "execution_count": 8, "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+-------+------+\n|overall| count|\n+-------+------+\n|    1.0|  9045|\n|    4.0| 64809|\n|    2.0| 10204|\n|    5.0|188208|\n+-------+------+\n\n"}], "source": "no_neutral_df.groupBy(\"overall\").count().show()"}, {"cell_type": "markdown", "metadata": {}, "source": "## Conversi\u00f3n de la valoraci\u00f3n num\u00e9rica en una etiqueta binaria"}, {"cell_type": "markdown", "metadata": {}, "source": "Vamos a crear, a partir de la columna `overall` que contiene la valoraci\u00f3n num\u00e9rica, una nueva columna binaria llamada `label` que ser\u00e1 la que utilice nuestros algoritmo predictivo. Para ello utilizaremos un `Binarizer` de Spark, fijando el umbral en 3.0 (que nunca se da en nuestros datos porque ya lo hab\u00edamos quitado). Todo valor por debajo de este umbral ser\u00e1 considerado como 0.0 y todo valor por encima ser\u00e1 convertido en 1.0. La columna original `overall` no se modifica."}, {"cell_type": "code", "execution_count": 9, "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+-------+-----+------+\n|overall|label| count|\n+-------+-----+------+\n|    2.0|  0.0| 10204|\n|    5.0|  1.0|188208|\n|    1.0|  0.0|  9045|\n|    4.0|  1.0| 64809|\n+-------+-----+------+\n\n"}], "source": "from pyspark.ml.feature import Binarizer\nimport numpy as np\n\nbinarizer = Binarizer(inputCol = \"overall\",\n                       outputCol = \"label\",\n                        threshold = 3.0)\n\nbinary_target_df = binarizer.transform(no_neutral_df)\nbinary_target_df.groupBy(\"overall\",\"label\").count().show()"}, {"cell_type": "markdown", "metadata": {}, "source": "## Muestreo estratificado\nComo suele ser habitual en los problemas de clasificaci\u00f3n binaria, existen muchos m\u00e1s ejemplos pertenecientes a una clase (en este caso la clase positiva) que a otra. Para que el modelo tambi\u00e9n sea sensible a ejemplos de la clase negativa, es conveniente tratar de equilibrar la proporci\u00f3n de ejemplos de cada clase presentes en nuestro conjunto de datos. Hay varias estrategias para conseguir esto. Aqu\u00ed optamos por la m\u00e1s simple (y a la vez, la menos recomendable en problemas reales) que es eliminar ejemplos de la clase mayoritaria.\n\nUtilizamos la funci\u00f3n `sampleBy()` indicando la fracci\u00f3n de ejemplos de cada clase que queremos mantener. En este caso queremos mantener todos los ejemplos de la clase negativa (que son minor\u00eda), pero tan s\u00f3lo queremos mantener el 10 % de los ejemplos de la clase mayoritaria. Si mostramos la cantidad de ejemplos en el DataFrame resultante de este muestreo, vemos que est\u00e1n m\u00e1s equilibrados aunque a\u00fan sigue ligeramente inclinado hacia la clase 1.0."}, {"cell_type": "code", "execution_count": 10, "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 17:=============================>                            (1 + 1) / 2]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-----+-----+\n|label|count|\n+-----+-----+\n|  0.0|19249|\n|  1.0|25269|\n+-----+-----+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "fractions = {1.0 : .1, 0.0 : 1.0}\nbalanced_df = binary_target_df.stat.sampleBy(\"label\", fractions, 36)\nbalanced_df.groupBy(\"label\").count().show()"}, {"cell_type": "markdown", "metadata": {}, "source": "Para poder saber c\u00f3mo de bien funcionar\u00e1 el modelo entrenado en datos nuevos nunca vistos, vamos a dividir el conjunto de datos en subconjuntos de entrenamiento y de test. El conjunto de test se utilizar\u00e1 una sola vez, al final, cuando ya tengamos decidido y entrenado el modelo de predicci\u00f3n. El objetivo del conjunto de test ser\u00e1 calcular una m\u00e9trica que estime la bondad del modelo cuando sea puesto en producci\u00f3n y empiece a predecir datos sobre los que realmente no se conoce su etiqueta.\n\nUsamos el 80 % de nuestros datos para entrenar, y el 20 % los dejamos fuera porque ser\u00e1n el conjunto de test."}, {"cell_type": "code", "execution_count": 11, "metadata": {"autoscroll": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 22:=============================>                            (1 + 1) / 2]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-----+-----+\n|label|count|\n+-----+-----+\n|  0.0|15416|\n|  1.0|20214|\n+-----+-----+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "split_seed = 5043\ntraining_data, test_data = balanced_df.randomSplit([0.8, 0.2], split_seed)\n\ntraining_data.cache()\ntraining_data.groupBy(\"label\").count().show()"}, {"cell_type": "markdown", "metadata": {}, "source": "## Ingenier\u00eda de variables y pipelines\n\nPara que las caracter\u00edsticas sean utilizadas por un algoritmo de aprendizaje autom\u00e1tico, deben transformarse y colocarse en vectores de caracter\u00edsticas, que son vectores num\u00e9ricos que representa el valor de cada caracter\u00edstica. Los textos en s\u00ed mismos no son utilizables por los algoritmos hasta que no pasen a trav\u00e9s de dicho proceso.\n\nSpark ML proporciona un conjunto uniforme de API de alto nivel creadas sobre DataFrames. Usaremos un ML Pipeline para pasar los datos a trav\u00e9s de transformadores con el fin de extraer las caracter\u00edsticas y un estimador para producir el modelo.\n\n* Transformador: Un transformador es un algoritmo que transforma un DataFrame en otro DataFrame. Usaremos un transformador para obtener un DataFrame con una columna de vector de caracter\u00edsticas.\n\n* Estimador: un estimador es un algoritmo que se puede ajustar a un DataFrame para producir un transformador. Usaremos un estimador que consistir\u00e1 en un algoritmo de Regresi\u00f3n log\u00edstica para entrenar un modelo. El modelo entrenado obtenido ser\u00e1 un transformador que es capaz de transformar datos sobre los que no se conoce su etiqueta, para calcular predicciones.\n\n* Pipeline: un pipeline encadena varios transformadores y estimadores para especificar un flujo de trabajo de aprendizaje autom\u00e1tico. Usaremos un Pipeline de Spark ML para tener en una sola pieza toda la secuencia de transformaciones necesarias para preparar los datos hasta llegar al modelo. De esa manera, podemos entrenar la pieza (el pipeline) como un todo, y utilizarlo para que los datos nuevos tambi\u00e9n pasen a trav\u00e9s de las mismas etapas que hab\u00edamos utilizado para preparar los datos de entrenamiento. Esto permite pre-procesar datos nuevos de la misma manera que se hizo con los datos de entrenamiento, siguiendo exactamente los mismos pasos.\n\nPor \u00faltimo utilizaremos un evaluador para medir la bondad del modelo entrenado."}, {"cell_type": "markdown", "metadata": {}, "source": "Empezaremos con las siguientes etapas de ingenier\u00eda de variables:\n\n* Primero utilizamos un `RegexTokenizer` para separar cada texto en palabras. Esto transforma cada texto en un vector de strings con las palabras. Para m\u00e1s detalles: http://spark.apache.org/docs/latest/ml-features.html#tokenizer\n* Despu\u00e9s aplicaremos un `StopWordsRemover` para eliminar de cada vector de palabras aquellas sin significado, como art\u00edculos, preposiciones, etc. Para m\u00e1s detalles: http://spark.apache.org/docs/latest/ml-features.html#stopwordsremover\n"}, {"cell_type": "code", "execution_count": 12, "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover\n\ntokenizer = RegexTokenizer(inputCol = \"reviewTS\",\n                               outputCol = \"reviewTokensUf\",\n                               pattern = \"\\\\s+|[,.()\\\"]\")\n\nremover = StopWordsRemover(inputCol = \"reviewTokensUf\",\n                           outputCol = \"reviewTokens\"\n                          ).setStopWords(StopWordsRemover.loadDefaultStopWords(\"english\"))"}, {"cell_type": "markdown", "metadata": {}, "source": "Utilizaremos el siguiente m\u00e9todo para convertir vectores de palabras de un texto en vectores num\u00e9ricos, utilizables por un algoritmo predictivo.\n\n**De la documentaci\u00f3n oficial de Spark**:\n\nTF-IDF es un m\u00e9todo de vectorizaci\u00f3n de caracter\u00edsticas ampliamente utilizado en la miner\u00eda de texto para reflejar la importancia de un t\u00e9rmino para un documento en el corpus. Si denotamos a un t\u00e9rmino (palabra) como *t*, un documento como *d* y el corpus como *D*, entonces:\n\n* La Frecuencia de un t\u00e9rmino **TF(*t*, *d*)** es el n\u00famero de veces que el t\u00e9rmino *t* aparece en el documento *d* \n* La frecuencia en el documento **DF(*t*, *D*)** es el n\u00famero de documentos que contienen el t\u00e9rmino *t*.\n\nSi solo usamos la frecuencia de los t\u00e9rminos para medir la importancia, es muy f\u00e1cil sobreenfatizar err\u00f3neamente los t\u00e9rminos que aparecen con mucha frecuencia pero que contienen poca informaci\u00f3n sobre el documento, p. Ej. la palabra *f\u00fatbol* en un corpus compuesto por biograf\u00edas de futbolistas. Si un t\u00e9rmino aparece con mucha frecuencia en el corpus, significa que no contiene informaci\u00f3n especial sobre un documento en particular. \n\n* La *frecuencia inversa de los documentos* **IDF(*t*, *D*)** es una medida num\u00e9rica de cu\u00e1nta informaci\u00f3n proporciona un t\u00e9rmino:\n\n$$ IDF (t, D) = \\frac{log | D | +1} {DF (t, D) +1} $$\n\ndonde | D | es el n\u00famero total de documentos del corpus. Dado que se usa logaritmo, si un t\u00e9rmino aparece en todos los documentos, su valor IDF se convierte en 0. Tenga en cuenta que se aplica un t\u00e9rmino de suavizado para evitar dividir por cero para los t\u00e9rminos fuera del corpus.\n\nLa medida TF-IDF es simplemente el producto de TF e IDF:\n$$ TFIDF (t, d, D) = TF (t, d) \u22c5 IDF (t, D) $$\n\nHay varias variantes en la definici\u00f3n de TF y de IDF. En Spark ML, est\u00e1n separados para que sean flexibles y poder combinarlos de varias maneras.\n\n* `CountVectorizer()` cuenta las ocurrencias totales de cada palabra en todo el corpus de textos, y se queda con las N m\u00e1s relevantes, siendo N un par\u00e1metro especificado por el usuario (en nuestro caso, N = 20000). Tras esto, en cada texto contar\u00e1 el n\u00famero de apariciones de cada una de esas N palabras seleccionadas. Por tanto, cada texto vendr\u00e1 representado por un vector num\u00e9rico de longitud 20000, y nuestro problema tendr\u00e1 20000 variables.\n\n* `HashingTF()` es similar, pero cada posici\u00f3n no se asocia a una sola palabra sino que puede estar compartida por m\u00e1s de una. El usuario especifica tambi\u00e9n la dimensi\u00f3n N de los vectores obtenidos (se recomienda que sea una potencia de 2 debido a c\u00f3mo act\u00faa esta t\u00e9cnica). A grandes rasgos, cada palabra se codifica mediante un c\u00f3digo que a su vez va a parar a una posici\u00f3n determinada del vector num\u00e9rico que va a representar a ese texto, por lo que puede haber colisiones en algunas ocasiones, y que una posici\u00f3n sea utilizada para acumular las apariciones de m\u00e1s de una palabra diferente.\n\nSe puede utilizar cualquiera de estas opciones, aunque no las dos simult\u00e1neamente."}, {"cell_type": "code", "execution_count": 13, "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "from pyspark.ml.feature import CountVectorizer, IDF, HashingTF\n\ncount_vectorizer = CountVectorizer().setInputCol(\"reviewTokens\")\\\n                                    .setOutputCol(\"cv\")\\\n                                    .setVocabSize(20000).setMinDF(4)\n\nidf = IDF().setInputCol(\"cv\").setOutputCol(\"features\")"}, {"cell_type": "code", "execution_count": 14, "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "from pyspark.ml.classification import LogisticRegression\n\n# El \u00faltimo elemento del pipeline ser\u00e1 un estimador, concretamente de la clase LogisticRegression\nlogisticRegression = LogisticRegression().setMaxIter(100)\\\n                                 .setRegParam(0.02)\\\n                                 .setElasticNetParam(0.3)"}, {"cell_type": "markdown", "metadata": {}, "source": "## Configuramos el pipeline"}, {"cell_type": "code", "execution_count": 16, "metadata": {"autoscroll": "auto"}, "outputs": [], "source": "from pyspark.ml import Pipeline\n\npipeline = Pipeline(stages = [tokenizer, remover, count_vectorizer, idf, logisticRegression])"}, {"cell_type": "markdown", "metadata": {}, "source": "### Entrenamos el pipeline, como un todo\n\nRecordemos que ahora mismo est\u00e1 activada la etapa `CountVectorizer`, con lo que ignoramos completamente el `HashingTF`. Nos servir\u00e1 en el futuro cuando queramos decidir cu\u00e1l de las dos opciones funciona mejor en base a su resultado."}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/03/18 08:57:30 WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n23/03/18 08:57:30 WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n                                                                                \r"}], "source": "pipelineModel = pipeline.fit(training_data)"}, {"cell_type": "code", "execution_count": 18, "metadata": {"autoscroll": "auto"}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>great</td>\n      <td>0.592809</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>returned</td>\n      <td>-0.377652</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>poor</td>\n      <td>-0.326958</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>perfect</td>\n      <td>0.320517</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>useless</td>\n      <td>-0.298490</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>waste</td>\n      <td>-0.286789</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>broke</td>\n      <td>-0.270305</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>easy</td>\n      <td>0.263212</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>junk</td>\n      <td>-0.255344</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>return</td>\n      <td>-0.254468</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>disappointed</td>\n      <td>-0.234911</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>love</td>\n      <td>0.231955</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>highly</td>\n      <td>0.230607</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>excellent</td>\n      <td>0.228914</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>disappointing</td>\n      <td>-0.225091</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>terrible</td>\n      <td>-0.216620</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>works</td>\n      <td>0.213106</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>returning</td>\n      <td>-0.209868</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>nice</td>\n      <td>0.209497</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>good</td>\n      <td>0.203303</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "             word    weight\n0           great  0.592809\n1        returned -0.377652\n2            poor -0.326958\n3         perfect  0.320517\n4         useless -0.298490\n5           waste -0.286789\n6           broke -0.270305\n7            easy  0.263212\n8            junk -0.255344\n9          return -0.254468\n10   disappointed -0.234911\n11           love  0.231955\n12         highly  0.230607\n13      excellent  0.228914\n14  disappointing -0.225091\n15       terrible -0.216620\n16          works  0.213106\n17      returning -0.209868\n18           nice  0.209497\n19           good  0.203303"}, "execution_count": 18, "metadata": {}, "output_type": "execute_result"}], "source": "import pandas as pd\n\nvocabulary = pipelineModel.stages[2].vocabulary\n\n# De la lista de stages, nos quedamos con el \u00faltimo elemento (LogisticRegressionModel, ya entrenado: transformador)\nlrModel = pipelineModel.stages[-1]\n\n# Obtenemos el array de coeficientes, que vienen en el mismo orden que las variables\nweights = lrModel.coefficients\n\n# Lista de pares (palabra, coeficiente) \nword_weight = list(zip(vocabulary,weights))\n\nword_weight.sort(key = lambda pair: np.abs(pair[1]), reverse = True)\n\n# Convertimos la lista de pares en un DataFrame para poder imprimirlo de manera m\u00e1s clara\nword_weight_df = pd.DataFrame(word_weight, columns = [\"word\", \"weight\"])[0:20]\nword_weight_df"}, {"cell_type": "markdown", "metadata": {}, "source": "# Predicciones en tiempo real con el modelo entrenado"}, {"cell_type": "markdown", "metadata": {}, "source": "Vamos a usar Spark Structured Streaming para hacer predicciones. Aunque los datos originales ten\u00edan dos columnas separadas `summary` y `reviewText`, desde el principio hab\u00edamos concatenado ambas en una sola columna `reviewTS` que es la que se utiliza como punto de partida en el pipeline, que no necesita para nada `reviewText` ni `summary`. Por tanto nuestros datos en streaming tendr\u00e1n una sola columna de tipo cadena de caracteres (string) llamada `reviewTS` que contiene en cada fila un texto completo (un string muy largo). \n\nTampoco necesitamos ninguna columna de `label` ni valoraci\u00f3n ni similar, puesto que son datos para predecir y asumimos que no tenemos por qu\u00e9 conocer dichos atributos."}, {"cell_type": "markdown", "metadata": {}, "source": "Vamos a dar cada dato como si fuera un JSON completo en una sola l\u00ednea. Despu\u00e9s despiezamos cada JSON (cada l\u00ednea) para pasarlo a un DataFrame de una columna de tipo string. Leermos cada JSON como una \u00fanica l\u00ednea de tipo string obtenida de Apache Kafka, configurando las siguientes opciones:\n\n  * Usamos la variable `readStream` (en lugar de `read` como solemos hacer) interna de la SparkSession `spark`\n  * Indicamos que el formato es `\"kafka\"` con `.format(\"kafka\")`\n  * Indicamos cu\u00e1les son los brokers de Kafka de los que vamos a leer y el puerto al que queremos conectarnos para leer (9092 es el que usa Kafka por defecto), con `.option(\"kafka.bootstrap.servers\", \"<nombre_cluster>-w-0:9092,<nombre_cluster>-w-1:9092\")`. De esa manera podremos leer el mensaje si el productor de Kafka lo env\u00eda a cualquiera de los dos brokers existentes, que son los nodos del cluster identificados como `<nombre_cluster>-w-0` y `<nombre_cluster>-w-1`\n  * Indicamos que queremos subscribirnos al topic `\"revisiones\"` con `.option(\"subscribe\", \"revisiones\")`.\n  * Finalmente ponemos `load()` para realizar la lectura."}, {"cell_type": "markdown", "metadata": {}, "source": "#### Creamos (desde l\u00ednea de comandos) el topic revisiones en Kafka\n`/usr/lib/kafka/bin/kafka-topics.sh --zookeeper localhost:2181 --create --replication-factor 1 --partitions 1 --topic revisiones`\n\n#### Vemos los topics existentes\n`/usr/lib/kafka/bin/kafka-topics.sh --zookeeper localhost:2181 --list`\n\n#### Abrimos el Kafka console producer (productor de Kafka desde consola, para enviarle mensajes al broker 0 del cluster de Kakfa)\n`/usr/lib/kafka/bin/kafka-console-producer.sh --broker-list <nombrecluster>-w-0:9092 --topic revisiones`\n\n#### Escribimos como mensajes: \n```\n{\"reviewTS\": \"This is an absolutely horrible product, what a shit!\"}\n{\"reviewTS\": \"The best purchase I have ever done, awesome\"}\n```"}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [], "source": "# Leemos de Kafka suscribi\u00e9ndonos al topic \"revisiones\" (revisiones de productos)\ntextosStreamingDF = spark.readStream\\\n  .format(\"kafka\")\\\n  .option(\"kafka.bootstrap.servers\", \"ucmcluster-w-0:9092,ucmcluster-w-1:9092\")\\\n  .option(\"subscribe\", \"revisiones\")\\\n  .load()"}, {"cell_type": "code", "execution_count": 20, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- key: binary (nullable = true)\n |-- value: binary (nullable = true)\n |-- topic: string (nullable = true)\n |-- partition: integer (nullable = true)\n |-- offset: long (nullable = true)\n |-- timestamp: timestamp (nullable = true)\n |-- timestampType: integer (nullable = true)\n\n"}], "source": "textosStreamingDF.printSchema()"}, {"cell_type": "code", "execution_count": 21, "metadata": {}, "outputs": [], "source": "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\nfrom pyspark.sql import functions as F\n\n# Este es el esquema de cada JSON: un \u00fanico campo. \n# Spark lo parsea como una columna de tipo estructura que dentro tiene un \u00fanico campo\nesquema = StructType([\\\n  StructField(\"reviewTS\", StringType())\\\n])\n\nparsedDF = textosStreamingDF\\\n    .withColumn(\"value\", F.col(\"value\").cast(StringType()))\\\n    .withColumn(\"reviewStruct\", F.from_json(F.col(\"value\"), esquema))\\\n    .withColumn(\"reviewTS\", F.col(\"reviewStruct.reviewTS\"))\n\npredictionsStreamingDF = pipelineModel.transform(parsedDF)"}, {"cell_type": "code", "execution_count": 22, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- key: binary (nullable = true)\n |-- value: string (nullable = true)\n |-- topic: string (nullable = true)\n |-- partition: integer (nullable = true)\n |-- offset: long (nullable = true)\n |-- timestamp: timestamp (nullable = true)\n |-- timestampType: integer (nullable = true)\n |-- reviewStruct: struct (nullable = true)\n |    |-- reviewTS: string (nullable = true)\n |-- reviewTS: string (nullable = true)\n\n"}], "source": "parsedDF.printSchema()"}, {"cell_type": "code", "execution_count": 23, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- key: binary (nullable = true)\n |-- value: string (nullable = true)\n |-- topic: string (nullable = true)\n |-- partition: integer (nullable = true)\n |-- offset: long (nullable = true)\n |-- timestamp: timestamp (nullable = true)\n |-- timestampType: integer (nullable = true)\n |-- reviewStruct: struct (nullable = true)\n |    |-- reviewTS: string (nullable = true)\n |-- reviewTS: string (nullable = true)\n |-- reviewTokensUf: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- reviewTokens: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- cv: vector (nullable = true)\n |-- features: vector (nullable = true)\n |-- rawPrediction: vector (nullable = true)\n |-- probability: vector (nullable = true)\n |-- prediction: double (nullable = false)\n\n"}], "source": "predictionsStreamingDF.printSchema()"}, {"cell_type": "code", "execution_count": 24, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/03/18 10:23:33 WARN org.apache.spark.sql.streaming.StreamingQueryManager: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-4b20346a-c1ef-4cab-8074-312d82a50085. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n23/03/18 10:23:33 WARN org.apache.spark.sql.streaming.StreamingQueryManager: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n                                                                                \r"}], "source": "output = predictionsStreamingDF\\\n                    .writeStream\\\n                    .queryName(\"predicciones\")\\\n                    .outputMode(\"append\")\\\n                    .format(\"memory\")\\\n                    .start()"}, {"cell_type": "code", "execution_count": 26, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----+--------------------------------------------------------------------+----------+---------+------+-----------------------+-------------+------------------------------------------------------+----------------------------------------------------+-------------------------------------------------------------+--------------------------------------+----------------------------------+-----------------------------------------------------------------------------+--------------------------------------+---------------------------------------+----------+\n|key |value                                                               |topic     |partition|offset|timestamp              |timestampType|reviewStruct                                          |reviewTS                                            |reviewTokensUf                                               |reviewTokens                          |cv                                |features                                                                     |rawPrediction                         |probability                            |prediction|\n+----+--------------------------------------------------------------------+----------+---------+------+-----------------------+-------------+------------------------------------------------------+----------------------------------------------------+-------------------------------------------------------------+--------------------------------------+----------------------------------+-----------------------------------------------------------------------------+--------------------------------------+---------------------------------------+----------+\n|null|{\"reviewTS\": \"This is an absolutely horrible product, what a shit!\"}|revisiones|0        |0     |2023-03-18 10:26:20.948|0            |{This is an absolutely horrible product, what a shit!}|This is an absolutely horrible product, what a shit!|[this, is, an, absolutely, horrible, product, what, a, shit!]|[absolutely, horrible, product, shit!]|(16553,[8,683,1021],[1.0,1.0,1.0])|(16553,[8,683,1021],[1.9435834257405933,4.360673905491399,4.839064253504237])|[0.621352878935338,-0.621352878935338]|[0.6505261772005493,0.3494738227994507]|0.0       |\n+----+--------------------------------------------------------------------+----------+---------+------+-----------------------+-------------+------------------------------------------------------+----------------------------------------------------+-------------------------------------------------------------+--------------------------------------+----------------------------------+-----------------------------------------------------------------------------+--------------------------------------+---------------------------------------+----------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "prediccionesDF = spark.sql(\"select * from predicciones\")\nprediccionesDF.show(truncate = False)"}, {"cell_type": "code", "execution_count": 27, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----+--------------------------------------------------------------------+----------+---------+------+-----------------------+-------------+------------------------------------------------------+----------------------------------------------------+-------------------------------------------------------------+--------------------------------------+--------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------+----------------------------------------+---------------------------------------+----------+\n|key |value                                                               |topic     |partition|offset|timestamp              |timestampType|reviewStruct                                          |reviewTS                                            |reviewTokensUf                                               |reviewTokens                          |cv                                                |features                                                                                                                 |rawPrediction                           |probability                            |prediction|\n+----+--------------------------------------------------------------------+----------+---------+------+-----------------------+-------------+------------------------------------------------------+----------------------------------------------------+-------------------------------------------------------------+--------------------------------------+--------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------+----------------------------------------+---------------------------------------+----------+\n|null|{\"reviewTS\": \"This is an absolutely horrible product, what a shit!\"}|revisiones|0        |0     |2023-03-18 10:26:20.948|0            |{This is an absolutely horrible product, what a shit!}|This is an absolutely horrible product, what a shit!|[this, is, an, absolutely, horrible, product, what, a, shit!]|[absolutely, horrible, product, shit!]|(16553,[8,683,1021],[1.0,1.0,1.0])                |(16553,[8,683,1021],[1.9435834257405933,4.360673905491399,4.839064253504237])                                            |[0.621352878935338,-0.621352878935338]  |[0.6505261772005493,0.3494738227994507]|0.0       |\n|null|{\"reviewTS\": \"The best purchase I have ever done, awesome\"}         |revisiones|0        |1     |2023-03-18 10:31:27.189|0            |{The best purchase I have ever done, awesome}         |The best purchase I have ever done, awesome         |[the, best, purchase, i, have, ever, done, awesome]          |[best, purchase, ever, done, awesome] |(16553,[77,183,185,272,321],[1.0,1.0,1.0,1.0,1.0])|(16553,[77,183,185,272,321],[2.7770611148260387,3.248238188264735,3.280546431497393,3.592398864876987,3.656597654399264])|[-1.2461287515653718,1.2461287515653718]|[0.22337098977942205,0.776629010220578]|1.0       |\n+----+--------------------------------------------------------------------+----------+---------+------+-----------------------+-------------+------------------------------------------------------+----------------------------------------------------+-------------------------------------------------------------+--------------------------------------+--------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------+----------------------------------------+---------------------------------------+----------+\n\n"}], "source": "prediccionesDF.show(truncate = False)"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.15"}}, "nbformat": 4, "nbformat_minor": 4}